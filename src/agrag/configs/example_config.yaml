data:
  chunk_size: 128
  chunk_overlap: 16
  data_dir: s3://autogluon-rag-github-dev/autogluon_docs/
  file_extns:
    - "pdf"
    - "txt"

embedding:
  embedding_model: BAAI/bge-large-en
  pooling_strategy: cls
  normalize_embeddings: false
  hf_model_params: null
  hf_tokenizer_init_params: null
  hf_tokenizer_params: 
    truncation: true
    padding: true
  hf_forward_params: null
  normalization_params: {'p': 2, 'dim': 1, 'eps': 1e-12}
  embedding_batch_size: 64

vector_db:
  db_type: faiss
  params: {gpu: False}
  similarity_threshold: 0.95
  similarity_fn: cosine
  use_existing_vector_db: true
  num_gpus: 0
  vector_db_index_path: s3://autogluon-rag-github-dev/vectorDB_index_save/faiss/index.idx
  metadata_index_path: s3://autogluon-rag-github-dev/vectorDB_metadata_save/faiss/metadata.json

retriever:
  top_k_embeddings: 20
  use_reranker: true
  reranker_model_name: BAAI/bge-large-en
  reranker_batch_size: 32
  num_gpus: 0
  reranker_hf_tokenizer_params:
    padding: true
    truncation: true
    max_length: 512
    return_tensors: pt

generator:
  generator_model_name: mistral.mistral-7b-instruct-v0:2
  use_bedrock: true
  bedrock_generate_params:
    max_tokens: 512
  openai_key_file: /Users/shriyen/Desktop/autogluon24/autogluon-rag/openai.txt
  generator_hf_generate_params:
    max_new_tokens: 1024
  generator_query_prefix: You are a helpful chat assistant. You will be provided with a query and you must answer it to the best of your abilities. You will be provided with some additional context that is related to the query and will help you answer the question.
